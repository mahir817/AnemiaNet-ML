{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize , find CR , Define weak features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Loaded Successfully.\n",
      "Train Shape: (4564, 96)\n",
      "✅ Data Normalized (Scaled).\n",
      "\n",
      "Potential Weak Features (Corr < 0.005):\n",
      "['floor_material_21.0', 'cooking_fuel_5.0', 'region_5.0', 'water_source_51.0', 'cooking_fuel_4.0', 'roof_material_32.0', 'water_source_32.0', 'household_size', 'cooking_fuel_96.0']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. LOAD THE DATA (The step that was missing)\n",
    "# Adjust the path if your folder name is different (e.g. 'processed' vs 'Splitted')\n",
    "TRAIN_X_PATH = \"../data/Splitted/X_train.csv\"\n",
    "TRAIN_Y_PATH = \"../data/Splitted/y_train.csv\"\n",
    "TEST_X_PATH =  \"../data/Splitted/X_test.csv\"\n",
    "TEST_Y_PATH =  \"../data/Splitted/y_test.csv\"\n",
    "\n",
    "# Load and flatten target variables (ravel)\n",
    "X_train = pd.read_csv(TRAIN_X_PATH)\n",
    "y_train = pd.read_csv(TRAIN_Y_PATH).values.ravel()\n",
    "X_test = pd.read_csv(TEST_X_PATH)\n",
    "y_test = pd.read_csv(TEST_Y_PATH).values.ravel()\n",
    "\n",
    "print(\"✅ Data Loaded Successfully.\")\n",
    "print(f\"Train Shape: {X_train.shape}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# NOW APPLY THE \"SENIOR'S ADVICE\" (Normalize & Correlate)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 2. Identify Numeric Columns\n",
    "# We normalize ONLY continuous values, not binary/dummy variables\n",
    "numeric_cols = [\n",
    "    'age', 'household_size', 'living_children',\n",
    "    'bmi', 'time_to_water', 'altitude'\n",
    "]\n",
    "# Safety filter: ensure they actually exist in your dataframe\n",
    "numeric_cols = [c for c in numeric_cols if c in X_train.columns]\n",
    "\n",
    "# 3. Apply Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create copies so we don't mess up the original X_train\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "print(\"✅ Data Normalized (Scaled).\")\n",
    "\n",
    "# 4. Check Correlations (To see what to drop)\n",
    "# Temporarily attach target to see correlations\n",
    "train_full = X_train_scaled.copy()\n",
    "train_full['TARGET'] = y_train\n",
    "\n",
    "correlations = train_full.corr()['TARGET'].sort_values(ascending=False)\n",
    "\n",
    "# Define weak features (Correlation extremely close to zero)\n",
    "threshold = 0.005\n",
    "weak_features = correlations[abs(correlations) < threshold].index.tolist()\n",
    "\n",
    "print(f\"\\nPotential Weak Features (Corr < {threshold}):\")\n",
    "print(weak_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surgical Dropping the true noise & Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 7 noise features.\n",
      "New Shape: (4564, 89)\n",
      "\n",
      "Training Refined Random Forest...\n",
      "--- REFINED RESULTS ---\n",
      "Old ROC-AUC: 0.5974\n",
      "New ROC-AUC: 0.5924\n",
      "⚖️ No significant change (or slight drop). The features were harmless.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, classification_report\n",
    "\n",
    "# 1. Define the specific list of Noise Features to drop\n",
    "# We EXCLUDE household_size and region from the drop list\n",
    "drop_list = [\n",
    "    'floor_material_21.0', \n",
    "    'cooking_fuel_5.0', \n",
    "    'water_source_51.0', \n",
    "    'cooking_fuel_4.0', \n",
    "    'roof_material_32.0', \n",
    "    'water_source_32.0', \n",
    "    'cooking_fuel_96.0'\n",
    "]\n",
    "\n",
    "# 2. Create Refined Datasets (Drop specific columns)\n",
    "# Ensure we only drop what actually exists (safety check)\n",
    "drop_actual = [c for c in drop_list if c in X_train_scaled.columns]\n",
    "\n",
    "X_train_refined = X_train_scaled.drop(columns=drop_actual)\n",
    "X_test_refined = X_test_scaled.drop(columns=drop_actual)\n",
    "\n",
    "print(f\"Dropped {len(drop_actual)} noise features.\")\n",
    "print(f\"New Shape: {X_train_refined.shape}\")\n",
    "\n",
    "# 3. RETRAIN Random Forest on Refined Data\n",
    "# We use the 'Aggressive' parameters from before (or close to them)\n",
    "print(\"\\nTraining Refined Random Forest...\")\n",
    "rf_refined = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,       # Allow full growth\n",
    "    min_samples_leaf=2,   # Slight constraint\n",
    "    max_features='sqrt',  # Standard\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_refined.fit(X_train_refined, y_train)\n",
    "\n",
    "# 4. Evaluate\n",
    "y_prob_refined = rf_refined.predict_proba(X_test_refined)[:, 1]\n",
    "auc_refined = roc_auc_score(y_test, y_prob_refined)\n",
    "\n",
    "print(f\"--- REFINED RESULTS ---\")\n",
    "print(f\"Old ROC-AUC: 0.5974\")\n",
    "print(f\"New ROC-AUC: {auc_refined:.4f}\")\n",
    "\n",
    "if auc_refined > 0.5974:\n",
    "    print(\"✅ Improvement! The noise removal helped.\")\n",
    "else:\n",
    "    print(\"⚖️ No significant change (or slight drop). The features were harmless.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering new features...\n",
      "New Feature Count: 99\n",
      "Added: interact_wealth_hsize, interact_rural_wealth, age_squared\n"
     ]
    }
   ],
   "source": [
    "# 1. Define a function to engineer features\n",
    "# This ensures we apply the EXACT same logic to Train and Test\n",
    "def engineer_features(df_input):\n",
    "    df = df_input.copy()\n",
    "    \n",
    "    # --- A. Medical Risk Flags ---\n",
    "    # Underweight Flag (BMI < 18.5 is a known anemia driver)\n",
    "    # Note: 'bmi' is scaled, so we must assume ~18.5 maps to a certain scaled value. \n",
    "    # OR, simpler: We create interactions based on the normalized distribution.\n",
    "    # Since we scaled data, we can't use \"18.5\" directly easily. \n",
    "    # Strategy: We will use Quantile interactions instead which are robust.\n",
    "    \n",
    "    # --- B. Socioeconomic Interactions (The \"Poverty Trap\") ---\n",
    "    # Interaction: Wealth * Household Size\n",
    "    # Rationale: Large families with low wealth spread nutrition thinner.\n",
    "    if 'wealth_index' in df.columns and 'household_size' in df.columns:\n",
    "        df['interact_wealth_hsize'] = df['wealth_index'] * df['household_size']\n",
    "\n",
    "    # --- C. Geographic-Economic Interaction ---\n",
    "    # Interaction: Rural (residence_2) * Wealth\n",
    "    # Note: Check your specific column name for Rural (e.g., 'residence_2' or similar)\n",
    "    # We'll try to find the 'Rural' dummy column dynamically\n",
    "    rural_col = [c for c in df.columns if 'residence' in c and '2' in c] # Usually residence_2\n",
    "    if rural_col and 'wealth_index' in df.columns:\n",
    "        df['interact_rural_wealth'] = df[rural_col[0]] * df['wealth_index']\n",
    "\n",
    "    # --- D. Age-Based Risk ---\n",
    "    # Adolescent Risk (Younger age often higher risk)\n",
    "    # Since Age is scaled, lower values = younger.\n",
    "    if 'age' in df.columns:\n",
    "        df['age_squared'] = df['age'] ** 2  # Capture non-linear age effects (U-shaped risk)\n",
    "\n",
    "    return df\n",
    "\n",
    "# 2. Apply to X_train and X_test\n",
    "print(\"Engineering new features...\")\n",
    "X_train_eng = engineer_features(X_train_scaled) # Use the scaled version you have\n",
    "X_test_eng  = engineer_features(X_test_scaled)\n",
    "\n",
    "print(f\"New Feature Count: {X_train_eng.shape[1]}\")\n",
    "print(\"Added: interact_wealth_hsize, interact_rural_wealth, age_squared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest on Engineered Features...\n",
      "--- ENGINEERED RESULTS ---\n",
      "Baseline ROC-AUC: 0.5974\n",
      "New ROC-AUC:      0.5888\n",
      "New PR-AUC:       0.4945\n",
      "\n",
      "Top 5 Features in New Model:\n",
      "bmi                      0.098374\n",
      "altitude                 0.074589\n",
      "age_squared              0.067918\n",
      "age                      0.067001\n",
      "interact_wealth_hsize    0.055534\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 3. Retrain RF on Engineered Data\n",
    "print(\"\\nTraining Random Forest on Engineered Features...\")\n",
    "\n",
    "rf_eng = RandomForestClassifier(\n",
    "    n_estimators=500,       # More trees to stabilize new features\n",
    "    max_depth=None,         # Let it find the deep interactions\n",
    "    min_samples_leaf=2,     # Keep it slightly flexible\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_eng.fit(X_train_eng, y_train)\n",
    "\n",
    "# 4. Evaluate\n",
    "y_prob_eng = rf_eng.predict_proba(X_test_eng)[:, 1]\n",
    "auc_eng = roc_auc_score(y_test, y_prob_eng)\n",
    "prauc_eng = average_precision_score(y_test, y_prob_eng)\n",
    "\n",
    "print(f\"--- ENGINEERED RESULTS ---\")\n",
    "print(f\"Baseline ROC-AUC: 0.5974\")\n",
    "print(f\"New ROC-AUC:      {auc_eng:.4f}\")\n",
    "print(f\"New PR-AUC:       {prauc_eng:.4f}\")\n",
    "\n",
    "# Check if the new features are actually being used\n",
    "importances = pd.Series(rf_eng.feature_importances_, index=X_train_eng.columns)\n",
    "print(\"\\nTop 5 Features in New Model:\")\n",
    "print(importances.sort_values(ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
